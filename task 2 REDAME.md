This task aims to analyze and classify news into two categories: reliable (0) and unreliable (1), using text analysis techniques and algorithms through:
Data preparation:

Data processing using techniques such as text cleaning, removing common unimportant words, and performing linguistic analysis using tools such as Stemming and Lemmatization from the NLTK library.
Data analysis:

Calculating text statistics (such as word count and average length).
Creating WordCloud to detect the most frequent words in reliable and unreliable news, and performing analysis to compare word patterns.
Modeling and classification:

Training a Naive Bayes model to classify news based on texts, and using several types of this model such as Complement NB, Multinomial NB, and Bernoulli NB.
Performance evaluation using confusion matrix, classification report, and ROC curves to compare models.
